# List of cloud hosts for inference and fine-tuning

A list of cloud hosting services offering resources for AI inference and fine-tuning:

## Hosts

### Inference:
1. [**Banana.dev**](https://banana.dev/): High-throughput inference hosting from GitHub repos.
2. [**Fal.ai**](https://fal.ai/): Hosts inference and generation services with open-source model playgrounds.
4. [**Lepton.ai**](https://lepton.ai/): Hosting and inference via CLI, easy HuggingFace model deployment.
5. [**Titanml.co**](https://titanml.co/): CLI and enterprise-focused inference deployments.

### Inference and Fine-Tuning:
1. [**Anyscale.com**](https://anyscale.com/): Inference and fine-tuning with shared endpoints for popular models.
2. [**Together.ai**](https://together.ai/): Provides inference and fine-tuning with multiple shared endpoints.
3. [**Brev.dev**](https://brev.dev/): Instance hosting and CLI tools, supports AWS and GCP deployment.
4. [**Replicate.com**](https://replicate.com/): Various preconfigured models and playgrounds for content generation.
5. [**Gradient.ai**](https://gradient.ai/): Fine-tuning focus via CLI, Python, and NodeJS.
6. [**Fireworks.ai**](https://fireworks.ai/): CLI-focused inference platform with shared endpoints.

## Table

| Service | Focus | GPU Types | Pricing | Additional Features |
|------------------|-------|-----------|---------|---------------------|
| [Banana.dev](https://www.banana.dev/) | High-throughput inference | Not specified | Scales to zero | Deploys from GitHub repo |
| [Fal.ai](https://www.fal.ai/) | Inference, image and audio generation | A100s, A10Gs, T4s | Scales to zero | Playgrounds and shared endpoints |
| [Replicate.com](https://replicate.com/) | Text, image, music, speech generation | A100s, A40s, T4s | [Scales to zero](https://replicate.com/pricing) | Preconfigured models and playgrounds |
| [Lepton.ai](https://www.lepton.ai/) | Hosting and inference via CLI | Not specified | [Scales to zero](https://www.lepton.ai/pricing) | Deploys HuggingFace models |
| [TitanML.co](https://titanml.co/) | CLI and enterprise inference deployments | Not specified | Not specified | - |
| [Anyscale.com](https://www.anyscale.com/endpoints) | Inference and fine-tuning | A10s, A100s, H100s (soon) | Not specified | Shared endpoints for various models |
| [Together.ai](https://www.together.ai/) | Inference and fine-tuning | A40s, A100s, H100s | [Scales to zero](https://www.together.ai/pricing) | 68 shared endpoints and playgrounds |
| [Brev.dev](https://brev.dev/) | Hosting and CLI tools | A100s, H100s, others | [Varies](https://brev.dev/pricing), Free for existing cloud | Deploys to AWS and GCP |
| [Gradient.ai](https://gradient.ai/) | Fine-tuning via CLI/Python/NodeJS | Not specified | Not specified | Online console for job management |
| [Fireworks.ai](https://fireworks.ai/) | CLI inference platform | Not specified | [Varies](https://readme.fireworks.ai/page/pricing) | Shared endpoints, supports LoRA addons |
